# OA CLI Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Build a zero-dependency, cross-platform coding-assistant CLI (`oa`) powered by the published `open_agent_sdk` package (default provider: RIGHTCODE), with a multi-turn REPL that supports colors on PowerShell/Linux/macOS.

**Architecture:** Implement a new Python package `open_agent_cli/` in this repo (installed alongside `open_agent_sdk`). Use `argparse` for subcommands, a small config layer that maps flags/env → `OpenAgentOptions`, and reuse `OpenAgentSDKClient` + `ConsoleRenderer` for streaming output. Add a tiny ANSI styling layer that auto-enables color (TTY) and enables VT processing on Windows when possible.

**Tech Stack:** Python 3.11+, stdlib only (`argparse`, `asyncio`, `json`, `pathlib`, `ctypes` on Windows), `open_agent_sdk` (imported as a normal installed package), `unittest`.

---

### Task 1: Add `open_agent_cli/` package scaffold

**Files:**
- Create: `open_agent_cli/__init__.py`
- Create: `open_agent_cli/__main__.py`
- Create: `open_agent_cli/args.py`
- Create: `open_agent_cli/config.py`

**Step 1: Write the failing test**

Create: `tests/test_cli_imports.py`

```py
import unittest


class TestCliImports(unittest.TestCase):
    def test_can_import_main(self) -> None:
        import open_agent_cli.__main__  # noqa: F401


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_imports`
Expected: FAIL (module not found)

**Step 3: Write minimal implementation**

- `open_agent_cli/__init__.py` sets `__all__` minimally.
- `open_agent_cli/__main__.py` defines `main(argv: list[str] | None = None) -> int` and calls it under `if __name__ == "__main__":`.
- `open_agent_cli/args.py` defines `build_parser()` returning an `argparse.ArgumentParser` with subcommands: `chat`, `run`, `resume`, `logs`.
- `open_agent_cli/config.py` defines helpers to build `OpenAgentOptions` (RIGHTCODE defaults).

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_imports`
Expected: PASS

---

### Task 2: Implement cross-platform color support (no third-party deps)

**Files:**
- Create: `open_agent_cli/style.py`
- Test: `tests/test_cli_style.py`

**Step 1: Write the failing test**

Create: `tests/test_cli_style.py`

```py
import os
import unittest


class TestCliStyle(unittest.TestCase):
    def test_no_color_env_disables_color(self) -> None:
        from open_agent_cli.style import StyleConfig, should_colorize

        os.environ["NO_COLOR"] = "1"
        try:
            self.assertFalse(should_colorize(StyleConfig(color="auto"), isatty=True, platform="linux"))
        finally:
            os.environ.pop("NO_COLOR", None)

    def test_color_always_enables_color(self) -> None:
        from open_agent_cli.style import StyleConfig, should_colorize

        self.assertTrue(should_colorize(StyleConfig(color="always"), isatty=False, platform="linux"))


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_style`
Expected: FAIL (missing module/functions)

**Step 3: Write minimal implementation**

In `open_agent_cli/style.py`:
- Define `StyleConfig(color: Literal["auto","always","never"])`.
- Define `should_colorize(config, *, isatty: bool, platform: str) -> bool` that:
  - returns `False` if `NO_COLOR` is set
  - returns `True` for `always`
  - returns `False` for `never`
  - returns `isatty` for `auto`
- Implement Windows VT enablement:
  - `enable_windows_vt_mode() -> bool` using `ctypes` (best-effort; safe no-op on non-Windows).
  - In `auto`, if platform is win32 and `isatty`, attempt enabling VT; if it fails, return `False`.
- Provide helpers to wrap strings with ANSI sequences (e.g., `fg_green`, `fg_red`, `dim`, `bold`) guarded by `should_colorize`.

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_style`
Expected: PASS

---

### Task 3: Implement config layer (RIGHTCODE defaults; published `open_agent_sdk` import)

**Files:**
- Modify: `open_agent_cli/config.py`
- Test: `tests/test_cli_config.py`

**Step 1: Write the failing test**

Create: `tests/test_cli_config.py`

```py
import os
import unittest


class TestCliConfig(unittest.TestCase):
    def test_rightcode_defaults(self) -> None:
        from open_agent_cli.config import build_options

        os.environ["RIGHTCODE_API_KEY"] = "x"
        try:
            opts = build_options(
                cwd=".",
                project_dir=".",
                permission_mode="prompt",
            )
            self.assertIsNotNone(opts.provider)
            self.assertEqual(opts.model, os.environ.get("RIGHTCODE_MODEL", "gpt-5.2"))
        finally:
            os.environ.pop("RIGHTCODE_API_KEY", None)


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_config`
Expected: FAIL (build_options missing)

**Step 3: Write minimal implementation**

In `open_agent_cli/config.py` implement:
- `require_env(name: str) -> str` (raise `SystemExit` with a helpful message).
- `build_provider_rightcode()` returning `OpenAICompatibleProvider` using:
  - `RIGHTCODE_BASE_URL` default `https://www.right.codes/codex/v1`
  - `RIGHTCODE_TIMEOUT_S` default `120`
  - `RIGHTCODE_MAX_RETRIES` default `2`
  - `RIGHTCODE_RETRY_BACKOFF_S` default `0.5`
- `build_options(cwd, project_dir, permission_mode, allowed_tools, session_root, resume, interactive)` returning `OpenAgentOptions` with:
  - `provider=build_provider_rightcode()`
  - `api_key=require_env("RIGHTCODE_API_KEY")`
  - `model=os.getenv("RIGHTCODE_MODEL","gpt-5.2")`
  - `setting_sources=["project"]`
  - `PermissionGate(permission_mode=..., interactive=...)`

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_config`
Expected: PASS

---

### Task 4: Implement `oa chat` (multi-turn REPL) with built-in slash commands

**Files:**
- Create: `open_agent_cli/repl.py`
- Modify: `open_agent_cli/__main__.py`
- Test: `tests/test_cli_repl_commands.py`

**Step 1: Write the failing test**

Create: `tests/test_cli_repl_commands.py`

```py
import unittest


class TestCliReplCommands(unittest.TestCase):
    def test_parse_repl_command(self) -> None:
        from open_agent_cli.repl import parse_repl_command

        self.assertEqual(parse_repl_command("/help"), ("help", ""))
        self.assertEqual(parse_repl_command("/skill main-process"), ("skill", "main-process"))


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_repl_commands`
Expected: FAIL

**Step 3: Write minimal implementation**

In `open_agent_cli/repl.py`:
- `parse_repl_command(line: str) -> tuple[str, str] | None`
- `run_chat(options, *, color_config, debug: bool, stdin, stdout) -> int`:
  - Uses `OpenAgentSDKClient(options)` and `await connect()`
  - Loop `input()` from stdin
  - Commands:
    - `/help` prints help
    - `/exit` exits
    - `/new` disconnects/reconnects, resets turn counter
    - `/interrupt` calls `client.interrupt()`
    - `/debug` toggles debug rendering
    - `/skills` prints local index via `open_agent_sdk.skills.index.index_skills(project_dir=...)` (no model call)
    - `/skill <name>` sends prompt `执行技能 <name>` (so the model + Skill tool loop is exercised)
    - `/cmd <name>` sends prompt `Run slash command <name>` (so the model may invoke `SlashCommand`)
  - Uses `ConsoleRenderer` for assistant output, but prints status lines with ANSI styling from `open_agent_cli/style.py`.
- Ensure Ctrl+C interrupts the in-flight request (call `client.interrupt()` then continue loop).

In `open_agent_cli/__main__.py`:
- Wire `chat` subcommand to call `asyncio.run(run_chat(...))`.

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_repl_commands`
Expected: PASS

**Step 5: Manual smoke test**

Run:
- `RIGHTCODE_API_KEY=... python -m open_agent_cli chat`
Expected:
- Colored prompts/status on terminals that support it
- `/skills` lists skills under the project’s `.claude/skills`
- `/skill main-process` shows “正在执行Skill：...” and the skill output

---

### Task 5: Implement `oa run` (one-shot) with optional JSON output

**Files:**
- Modify: `open_agent_cli/__main__.py`
- Create: `open_agent_cli/run_cmd.py`
- Test: `tests/test_cli_run_json.py`

**Step 1: Write the failing test**

Create: `tests/test_cli_run_json.py`

```py
import json
import unittest


class TestCliRunJson(unittest.TestCase):
    def test_json_shape(self) -> None:
        from open_agent_cli.run_cmd import format_run_json

        s = format_run_json(final_text="ok", session_id="sid", stop_reason="end")
        obj = json.loads(s)
        self.assertEqual(obj["final_text"], "ok")
        self.assertEqual(obj["session_id"], "sid")


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_run_json`
Expected: FAIL

**Step 3: Write minimal implementation**

In `open_agent_cli/run_cmd.py`:
- `format_run_json(...) -> str` returns JSON with keys: `final_text`, `session_id`, `stop_reason`.
- `async run_once(options, prompt, *, stream: bool, json_output: bool) -> int`:
  - For `stream=True`, use `open_agent_sdk.console.console_query(...)`
  - For `stream=False`, use `open_agent_sdk.run(...)` and print final text (or JSON).

In `open_agent_cli/__main__.py`:
- Add `oa run "<prompt>"` parsing:
  - `--json`
  - `--stream/--no-stream` (default stream on)

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_run_json`
Expected: PASS

---

### Task 6: Implement `oa resume` as a `chat --resume <id>` alias

**Files:**
- Modify: `open_agent_cli/args.py`
- Modify: `open_agent_cli/__main__.py`
- Test: `tests/test_cli_args.py`

**Step 1: Write the failing test**

Create: `tests/test_cli_args.py`

```py
import unittest


class TestCliArgs(unittest.TestCase):
    def test_resume_parses_session_id(self) -> None:
        from open_agent_cli.args import parse_args

        ns = parse_args(["resume", "abc123"])
        self.assertEqual(ns.command, "resume")
        self.assertEqual(ns.session_id, "abc123")


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_args`
Expected: FAIL

**Step 3: Write minimal implementation**

In `open_agent_cli/args.py`:
- Implement `parse_args(argv)` and ensure `resume <session_id>` populates `ns.session_id`.

In `open_agent_cli/__main__.py`:
- For `resume`, call `chat` with `options.resume=session_id` and show a status line.

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_args`
Expected: PASS

---

### Task 7: Implement `oa logs <session_id>` (read `events.jsonl` and summarize)

**Files:**
- Create: `open_agent_cli/logs_cmd.py`
- Modify: `open_agent_cli/__main__.py`
- Test: `tests/test_cli_logs_summary.py`

**Step 1: Write the failing test**

Create: `tests/test_cli_logs_summary.py`

```py
import unittest
from pathlib import Path
from tempfile import TemporaryDirectory

from open_agent_sdk.sessions.store import FileSessionStore
from open_agent_sdk.events import UserMessage


class TestCliLogsSummary(unittest.TestCase):
    def test_summarize_events_basic(self) -> None:
        from open_agent_cli.logs_cmd import summarize_events

        with TemporaryDirectory() as td:
            root = Path(td)
            store = FileSessionStore(root_dir=root)
            sid = store.create_session(metadata={"cwd": str(root)})
            store.append_event(sid, UserMessage(text="hi"))

            events = store.read_events(sid)
            out = summarize_events(events)
            self.assertIn("user.message", out)


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_logs_summary`
Expected: FAIL

**Step 3: Write minimal implementation**

In `open_agent_cli/logs_cmd.py`:
- `summarize_events(events) -> str` produces a compact summary:
  - counts by event type
  - last 10 tool uses/results (tool name + success/error)
  - last result stop_reason
- Optionally colorize labels if enabled.

In `open_agent_cli/__main__.py`:
- Implement `oa logs <session_id> [--session-root <path>]`
  - Use `FileSessionStore(root_dir=...)` and `read_events(session_id)`.

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_logs_summary`
Expected: PASS

---

### Task 8: Wire packaging + docs for `oa`

**Files:**
- Modify: `pyproject.toml`
- Modify: `README.md`
- Modify: `README.zh_cn.md`

**Step 1: Write the failing test**

Create: `tests/test_cli_entrypoint_docs.py`

```py
import unittest


class TestCliEntrypointDocs(unittest.TestCase):
    def test_cli_main_exists(self) -> None:
        from open_agent_cli.__main__ import main

        self.assertTrue(callable(main))


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run test to verify it fails**

Run: `python3 -m unittest -q tests.test_cli_entrypoint_docs`
Expected: FAIL until CLI exists/wired

**Step 3: Write minimal implementation**

- In `pyproject.toml`:
  - Add `open_agent_cli*` to package discovery.
  - Add `[project.scripts] oa = "open_agent_cli.__main__:main"`.
- In `README.md` and `README.zh_cn.md`:
  - Document installation + `oa chat/run/resume/logs`.

**Step 4: Run test to verify it passes**

Run: `python3 -m unittest -q tests.test_cli_entrypoint_docs`
Expected: PASS

---

## Final verification (before claiming done)

Run:
- `python3 -m unittest -q`
- `python3 -m py_compile $(python3 - <<'PY'\nimport subprocess\nprint(' '.join(subprocess.check_output(['git','ls-files','-z'], text=False).decode().split('\\0')))\nPY)`

Manual smoke tests:
- PowerShell: `oa chat` shows color (or cleanly falls back to no color if unsupported).
- Linux/macOS: `oa chat` shows color, `/interrupt` works, `/new` starts fresh, `oa logs <sid>` renders a useful summary.

